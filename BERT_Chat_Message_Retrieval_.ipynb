{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Chat Message Retrieval .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYapTjoYa0kO"
      },
      "source": [
        "# Introduction\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RfUN_KolV-f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87cf3706-05a1-4c3b-a2d5-1b9a9a9b4877"
      },
      "source": [
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 30 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 123 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.62.3)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.20.20-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 42.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.10.0.2)\n",
            "Collecting botocore<1.24.0,>=1.23.20\n",
            "  Downloading botocore-1.23.20-py3-none-any.whl (8.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 45.2 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.20->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 44.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.20->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.10.8)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 50.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.20.20 botocore-1.23.20 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.5.0 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJEnBJ3gHTsQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a67a9bf8-0d0b-4f7d-f151-ff9b25215b94"
      },
      "source": [
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "\n",
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "#logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 2082494.09B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TAsqbiTllM2",
        "outputId": "416a5c5f-d4be-4de2-ce2a-9d3f4222ec16"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tlv3VlPnKKHN"
      },
      "source": [
        "# 2. Input Formatting\n",
        "Because BERT is a pretrained model that expects input data in a specific format, we will need:\n",
        "\n",
        "- special tokens to mark the beginning ([CLS]) and separation/end of sentences ([SEP])\n",
        "- tokens that conforms with the fixed vocabulary used in BERT\n",
        "- token IDs from BERT's tokenizer\n",
        "- mask IDs to indicate which elements in the sequence are tokens and which are padding elements\n",
        "- segment IDs used to distinguish different sentences\n",
        "- positional embeddings used to show token position within the sequence\n",
        "\n",
        "Luckily, this interface takes care of some of these input specifications for us so we will only have to manually create a few of them (we'll revisit the other inputs in another tutorial).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gsyrAwYvBfC"
      },
      "source": [
        "## 2.2. Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5vYaUMpTEbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb62bad1-b8ea-456b-ec0f-bfd24b877999"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "stop_words = set(stopwords.words('english'))\n",
        "from nltk import tokenize\n",
        "from operator import itemgetter\n",
        "import math\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MogF351iTKJd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "outputId": "8660b434-7362-4312-cf38-183e7b88d720"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/conversation.csv\")\n",
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user1</th>\n",
              "      <th>user2</th>\n",
              "      <th>message</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>John</td>\n",
              "      <td>Rahul</td>\n",
              "      <td>To maintain a healthy diet is really important</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rahul</td>\n",
              "      <td>John</td>\n",
              "      <td>I agree with you.  But the worst part is that ...</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>John</td>\n",
              "      <td>Rahul</td>\n",
              "      <td>Yeah. It happens.</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rahul</td>\n",
              "      <td>John</td>\n",
              "      <td>I hope there was a solution to this</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>John</td>\n",
              "      <td>Rahul</td>\n",
              "      <td>Ofcourse. You can choose many other options.</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Rahul</td>\n",
              "      <td>John</td>\n",
              "      <td>Like what?</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>John</td>\n",
              "      <td>Rahul</td>\n",
              "      <td>Do you like fruits?</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Rahul</td>\n",
              "      <td>John</td>\n",
              "      <td>Yes. I do.</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>John</td>\n",
              "      <td>Rahul</td>\n",
              "      <td>Fruits contain many nutrients. And it may help...</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Rahul</td>\n",
              "      <td>John</td>\n",
              "      <td>Yeah. I haven't thought about it yet.</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>John</td>\n",
              "      <td>Rahul</td>\n",
              "      <td>I actually love apples</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Rahul</td>\n",
              "      <td>John</td>\n",
              "      <td>And an apple a day keeps the doctor away.</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>John</td>\n",
              "      <td>Rahul</td>\n",
              "      <td>Yes. Definitely.</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Rahul</td>\n",
              "      <td>John</td>\n",
              "      <td>I also love apples. And the dry fruits too.</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>John</td>\n",
              "      <td>Rahul</td>\n",
              "      <td>Here you go. You found the solution yourself.</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Rahul</td>\n",
              "      <td>John</td>\n",
              "      <td>Haha. Yes</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>John</td>\n",
              "      <td>Peter</td>\n",
              "      <td>How can I help you?</td>\n",
              "      <td>22-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Peter</td>\n",
              "      <td>John</td>\n",
              "      <td>What all products do you have?</td>\n",
              "      <td>22-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>John</td>\n",
              "      <td>Peter</td>\n",
              "      <td>Apple Iphone, MacBook, Airpod, AirBook</td>\n",
              "      <td>22-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Peter</td>\n",
              "      <td>John</td>\n",
              "      <td>What kind of phones do you have?</td>\n",
              "      <td>22-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>John</td>\n",
              "      <td>Peter</td>\n",
              "      <td>We do have different models of Apple phones wi...</td>\n",
              "      <td>22-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Peter</td>\n",
              "      <td>John</td>\n",
              "      <td>Can you suggest me the best models</td>\n",
              "      <td>22-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>John</td>\n",
              "      <td>Peter</td>\n",
              "      <td>Sure.</td>\n",
              "      <td>22-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Della</td>\n",
              "      <td>John</td>\n",
              "      <td>Hello John.</td>\n",
              "      <td>23-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>John</td>\n",
              "      <td>Della</td>\n",
              "      <td>Hi. Nice to meet you</td>\n",
              "      <td>23-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Della</td>\n",
              "      <td>John</td>\n",
              "      <td>How is the partnership with ABC company</td>\n",
              "      <td>23-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>John</td>\n",
              "      <td>Della</td>\n",
              "      <td>It is actually amazing. And we are very gratef...</td>\n",
              "      <td>23-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Della</td>\n",
              "      <td>John</td>\n",
              "      <td>Thats great.</td>\n",
              "      <td>23-11-2021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    user1  user2                                            message        date\n",
              "0    John  Rahul     To maintain a healthy diet is really important  20-11-2021\n",
              "1   Rahul   John  I agree with you.  But the worst part is that ...  20-11-2021\n",
              "2    John  Rahul                                 Yeah. It happens.   20-11-2021\n",
              "3   Rahul   John                I hope there was a solution to this  20-11-2021\n",
              "4    John  Rahul      Ofcourse. You can choose many other options.   20-11-2021\n",
              "5   Rahul   John                                         Like what?  20-11-2021\n",
              "6    John  Rahul                                Do you like fruits?  20-11-2021\n",
              "7   Rahul   John                                         Yes. I do.  20-11-2021\n",
              "8    John  Rahul  Fruits contain many nutrients. And it may help...  20-11-2021\n",
              "9   Rahul   John              Yeah. I haven't thought about it yet.  20-11-2021\n",
              "10   John  Rahul                             I actually love apples  20-11-2021\n",
              "11  Rahul   John          And an apple a day keeps the doctor away.  20-11-2021\n",
              "12   John  Rahul                                   Yes. Definitely.  20-11-2021\n",
              "13  Rahul   John        I also love apples. And the dry fruits too.  20-11-2021\n",
              "14   John  Rahul      Here you go. You found the solution yourself.  20-11-2021\n",
              "15  Rahul   John                                          Haha. Yes  20-11-2021\n",
              "16    NaN    NaN                                                NaN         NaN\n",
              "17   John  Peter                                How can I help you?  22-11-2021\n",
              "18  Peter   John                     What all products do you have?  22-11-2021\n",
              "19   John  Peter             Apple Iphone, MacBook, Airpod, AirBook  22-11-2021\n",
              "20  Peter   John                   What kind of phones do you have?  22-11-2021\n",
              "21   John  Peter  We do have different models of Apple phones wi...  22-11-2021\n",
              "22  Peter   John                 Can you suggest me the best models  22-11-2021\n",
              "23   John  Peter                                              Sure.  22-11-2021\n",
              "24    NaN    NaN                                                NaN         NaN\n",
              "25  Della   John                                        Hello John.  23-11-2021\n",
              "26   John  Della                               Hi. Nice to meet you  23-11-2021\n",
              "27  Della   John           How is the partnership with ABC company   23-11-2021\n",
              "28   John  Della  It is actually amazing. And we are very gratef...  23-11-2021\n",
              "29  Della   John                                       Thats great.  23-11-2021"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK2ihbHyS5UL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5c542916-a2c9-4073-ae8c-d2bcc92205a8"
      },
      "source": [
        "df=df.dropna()\n",
        "df[\"message\"]=df[\"message\"].str.lower()\n",
        "df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user1</th>\n",
              "      <th>user2</th>\n",
              "      <th>message</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>John</td>\n",
              "      <td>Rahul</td>\n",
              "      <td>to maintain a healthy diet is really important</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Rahul</td>\n",
              "      <td>John</td>\n",
              "      <td>i agree with you.  but the worst part is that ...</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>John</td>\n",
              "      <td>Rahul</td>\n",
              "      <td>yeah. it happens.</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rahul</td>\n",
              "      <td>John</td>\n",
              "      <td>i hope there was a solution to this</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>John</td>\n",
              "      <td>Rahul</td>\n",
              "      <td>ofcourse. you can choose many other options.</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Rahul</td>\n",
              "      <td>John</td>\n",
              "      <td>like what?</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>John</td>\n",
              "      <td>Rahul</td>\n",
              "      <td>do you like fruits?</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Rahul</td>\n",
              "      <td>John</td>\n",
              "      <td>yes. i do.</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>John</td>\n",
              "      <td>Rahul</td>\n",
              "      <td>fruits contain many nutrients. and it may help...</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Rahul</td>\n",
              "      <td>John</td>\n",
              "      <td>yeah. i haven't thought about it yet.</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>John</td>\n",
              "      <td>Rahul</td>\n",
              "      <td>i actually love apples</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Rahul</td>\n",
              "      <td>John</td>\n",
              "      <td>and an apple a day keeps the doctor away.</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>John</td>\n",
              "      <td>Rahul</td>\n",
              "      <td>yes. definitely.</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Rahul</td>\n",
              "      <td>John</td>\n",
              "      <td>i also love apples. and the dry fruits too.</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>John</td>\n",
              "      <td>Rahul</td>\n",
              "      <td>here you go. you found the solution yourself.</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Rahul</td>\n",
              "      <td>John</td>\n",
              "      <td>haha. yes</td>\n",
              "      <td>20-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>John</td>\n",
              "      <td>Peter</td>\n",
              "      <td>how can i help you?</td>\n",
              "      <td>22-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Peter</td>\n",
              "      <td>John</td>\n",
              "      <td>what all products do you have?</td>\n",
              "      <td>22-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>John</td>\n",
              "      <td>Peter</td>\n",
              "      <td>apple iphone, macbook, airpod, airbook</td>\n",
              "      <td>22-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Peter</td>\n",
              "      <td>John</td>\n",
              "      <td>what kind of phones do you have?</td>\n",
              "      <td>22-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>John</td>\n",
              "      <td>Peter</td>\n",
              "      <td>we do have different models of apple phones wi...</td>\n",
              "      <td>22-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Peter</td>\n",
              "      <td>John</td>\n",
              "      <td>can you suggest me the best models</td>\n",
              "      <td>22-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>John</td>\n",
              "      <td>Peter</td>\n",
              "      <td>sure.</td>\n",
              "      <td>22-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Della</td>\n",
              "      <td>John</td>\n",
              "      <td>hello john.</td>\n",
              "      <td>23-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>John</td>\n",
              "      <td>Della</td>\n",
              "      <td>hi. nice to meet you</td>\n",
              "      <td>23-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Della</td>\n",
              "      <td>John</td>\n",
              "      <td>how is the partnership with abc company</td>\n",
              "      <td>23-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>John</td>\n",
              "      <td>Della</td>\n",
              "      <td>it is actually amazing. and we are very gratef...</td>\n",
              "      <td>23-11-2021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Della</td>\n",
              "      <td>John</td>\n",
              "      <td>thats great.</td>\n",
              "      <td>23-11-2021</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    user1  user2                                            message        date\n",
              "0    John  Rahul     to maintain a healthy diet is really important  20-11-2021\n",
              "1   Rahul   John  i agree with you.  but the worst part is that ...  20-11-2021\n",
              "2    John  Rahul                                 yeah. it happens.   20-11-2021\n",
              "3   Rahul   John                i hope there was a solution to this  20-11-2021\n",
              "4    John  Rahul      ofcourse. you can choose many other options.   20-11-2021\n",
              "5   Rahul   John                                         like what?  20-11-2021\n",
              "6    John  Rahul                                do you like fruits?  20-11-2021\n",
              "7   Rahul   John                                         yes. i do.  20-11-2021\n",
              "8    John  Rahul  fruits contain many nutrients. and it may help...  20-11-2021\n",
              "9   Rahul   John              yeah. i haven't thought about it yet.  20-11-2021\n",
              "10   John  Rahul                             i actually love apples  20-11-2021\n",
              "11  Rahul   John          and an apple a day keeps the doctor away.  20-11-2021\n",
              "12   John  Rahul                                   yes. definitely.  20-11-2021\n",
              "13  Rahul   John        i also love apples. and the dry fruits too.  20-11-2021\n",
              "14   John  Rahul      here you go. you found the solution yourself.  20-11-2021\n",
              "15  Rahul   John                                          haha. yes  20-11-2021\n",
              "17   John  Peter                                how can i help you?  22-11-2021\n",
              "18  Peter   John                     what all products do you have?  22-11-2021\n",
              "19   John  Peter             apple iphone, macbook, airpod, airbook  22-11-2021\n",
              "20  Peter   John                   what kind of phones do you have?  22-11-2021\n",
              "21   John  Peter  we do have different models of apple phones wi...  22-11-2021\n",
              "22  Peter   John                 can you suggest me the best models  22-11-2021\n",
              "23   John  Peter                                              sure.  22-11-2021\n",
              "25  Della   John                                        hello john.  23-11-2021\n",
              "26   John  Della                               hi. nice to meet you  23-11-2021\n",
              "27  Della   John           how is the partnership with abc company   23-11-2021\n",
              "28   John  Della  it is actually amazing. and we are very gratef...  23-11-2021\n",
              "29  Della   John                                       thats great.  23-11-2021"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3dtItfDT-0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60b030d0-ded2-4b49-8225-0992527b0546"
      },
      "source": [
        "query=input(\"What you want to know :\")\n",
        "words = tokenizer.tokenize(query)\n",
        "keywords=[]\n",
        "for i in words:\n",
        "  if len(i)>3:\n",
        "    keywords.append(i)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What you want to know :what was the conversation regarding apple phone?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2pghluPYgkt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99bd6a2b-d31f-4e83-f313-2ce6322331dc"
      },
      "source": [
        "keywords"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['what', 'conversation', 'regarding', 'apple', 'phone']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBSIBD8SYo22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "37673ea1-5b2c-4136-b7db-41ba9c5e2ac4"
      },
      "source": [
        "df_new = df[df['user1'] == 'John']\n",
        "results=[]    \n",
        "for i in df_new[\"message\"]:\n",
        "  if \"apple\" in i:    \n",
        "    results.append(i)\n",
        "\n",
        "results.append(query)\n",
        "print(results)  \n",
        "res = '. '.join(map(str, results))\n",
        "res"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i actually love apples', 'apple iphone, macbook, airpod, airbook', 'we do have different models of apple phones with us', 'what was the conversation regarding apple phone?']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i actually love apples. apple iphone, macbook, airpod, airbook. we do have different models of apple phones with us. what was the conversation regarding apple phone?'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYjcYJuXoAQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c775dc9e-9369-4339-d8f7-f41254db062b"
      },
      "source": [
        "\n",
        "# Add the special tokens.\n",
        "marked_text = \"[CLS] \" + res + \" [SEP]\"\n",
        "\n",
        "# Split the sentence into tokens.\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "# Map the token strings to their vocabulary indeces.\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "# Display the words with their indeces.\n",
        "for tup in zip(tokenized_text, indexed_tokens):\n",
        "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n",
        "    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]           101\n",
            "i             1,045\n",
            "actually      2,941\n",
            "love          2,293\n",
            "apples       18,108\n",
            ".             1,012\n",
            "apple         6,207\n",
            "iphone       18,059\n",
            ",             1,010\n",
            "mac           6,097\n",
            "##book        8,654\n",
            ",             1,010\n",
            "air           2,250\n",
            "##pod        27,633\n",
            ",             1,010\n",
            "air           2,250\n",
            "##book        8,654\n",
            ".             1,012\n",
            "we            2,057\n",
            "do            2,079\n",
            "have          2,031\n",
            "different     2,367\n",
            "models        4,275\n",
            "of            1,997\n",
            "apple         6,207\n",
            "phones       11,640\n",
            "with          2,007\n",
            "us            2,149\n",
            ".             1,012\n",
            "what          2,054\n",
            "was           2,001\n",
            "the           1,996\n",
            "conversation  4,512\n",
            "regarding     4,953\n",
            "apple         6,207\n",
            "phone         3,042\n",
            "?             1,029\n",
            "[SEP]           102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_jEkVKxJMc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5d9181d-9ee6-4bb7-eaf3-fd754a27ae13"
      },
      "source": [
        "# Mark each of the tokens as belonging to sentence \"1\".\n",
        "segments_ids = [1] * len(tokenized_text)\n",
        "\n",
        "print (segments_ids)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-nY9LASLr2L"
      },
      "source": [
        "# 3. Extracting Embeddings \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl-iCj8wMEd5"
      },
      "source": [
        "## 3.1. Running BERT on our text\n",
        "\n",
        "Next we need to convert our data to torch tensors and call the BERT model. The BERT PyTorch interface requires that the data be in torch tensors rather than Python lists, so we convert the lists here - this does not change the shape or the data.\n",
        " \n",
        "model.eval() puts our model in evaluation mode as opposed to training mode. In this case, evaluation mode turns off dropout regularization which is used in training.\n",
        "\n",
        "Calling `from_pretrained` will fetch the model from the internet. When we load the `bert-base-uncased`, we see the definition of the model printed in the logging. The model is a deep neural network with 12 layers! Explaining the layers and their functions is outside the scope of this post, and you can skip over this output for now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_t4cM6KLc98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc57f0f-4f7d-4c44-e538-c61848bd14cd"
      },
      "source": [
        "# Convert inputs to PyTorch tensors\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "segments_tensors = torch.tensor([segments_ids])\n",
        "\n",
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407873900/407873900 [00:11<00:00, 35980786.79B/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): BertLayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4Qa5KkkM2Aq"
      },
      "source": [
        "Next, let's fetch the hidden states of the network.\n",
        "\n",
        "torch.no_grad deactivates the gradient calculations, saves memory, and speeds up computation (we don't need gradients or backpropagation since we're just running a forward pass). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN0QTZwiMzeq"
      },
      "source": [
        "# Predict hidden states features for each layer\n",
        "with torch.no_grad():\n",
        "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI_uxiW7eRWA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50799720-1688-4fe3-ca2a-6219b15e9f6f"
      },
      "source": [
        "print (\"Number of layers:\", len(encoded_layers))\n",
        "layer_i = 0\n",
        "\n",
        "print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
        "batch_i = 0\n",
        "\n",
        "print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
        "token_i = 0\n",
        "\n",
        "print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of layers: 12\n",
            "Number of batches: 1\n",
            "Number of tokens: 38\n",
            "Number of hidden units: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UF_OAO-S1sP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "outputId": "78d02c6e-0345-45d2-eb2f-445284ee29b6"
      },
      "source": [
        "# For the 5th token in our sentence, select its feature values from layer 5.\n",
        "token_i = 5\n",
        "layer_i = 5\n",
        "vec = encoded_layers[layer_i][batch_i][token_i]\n",
        "\n",
        "# Plot the values as a histogram to show their distribution.\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.hist(vec, bins=200)\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n194RcReDYfw"
      },
      "source": [
        "Grouping the values by layer makes sense for the model, but for our purposes we want it grouped by token. \n",
        "\n",
        "Current dimensions:\n",
        "\n",
        "`[# layers, # batches, # tokens, # features]`\n",
        "\n",
        "Desired dimensions:\n",
        "\n",
        "`[# tokens, # layers, # features]`\n",
        "\n",
        "Luckily, PyTorch includes the `permute` function for easily rearranging the dimensions of a tensor. \n",
        "\n",
        "However, the first dimension is currently a Python list! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CcY_oRwcHlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbf54d50-1813-458c-8b21-30f709550bd2"
      },
      "source": [
        "# `encoded_layers` is a Python list.\n",
        "print('     Type of encoded_layers: ', type(encoded_layers))\n",
        "\n",
        "# Each layer in the list is a torch tensor.\n",
        "print('Tensor shape for each layer: ', encoded_layers[0].size())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Type of encoded_layers:  <class 'list'>\n",
            "Tensor shape for each layer:  torch.Size([1, 38, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yXZjLSke3F0"
      },
      "source": [
        "Let's combine the 12 layers to make this one whole big tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTJV8AFFcLbL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f58e4d29-aa72-4138-d974-f3adc031c501"
      },
      "source": [
        "# Concatenate the tensors for all layers. We use `stack` here to\n",
        "# create a new dimension in the tensor.\n",
        "token_embeddings = torch.stack(encoded_layers, dim=0)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 1, 38, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnBv2TUNhzf4"
      },
      "source": [
        "Let's get rid of the \"batches\" dimension since we don't need it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En4JZ41fh6CI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "669fd3f6-e7a6-4464-f704-976228124783"
      },
      "source": [
        "# Remove dimension 1, the \"batches\".\n",
        "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 38, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVzRfvkbe-Yp"
      },
      "source": [
        "Finally, we can switch around the \"layers\" and \"tokens\" dimensions with `permute`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtDVE58cdeYp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ba545e8-4b55-4ae5-d5f1-0d2b442b51fe"
      },
      "source": [
        "# Swap dimensions 0 and 1.\n",
        "token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "token_embeddings.size()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([38, 12, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pv42h9jANMRf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458cdb5d-8fa5-4022-e674-90bb298db4b5"
      },
      "source": [
        "# Stores the token vectors, with shape [22 x 3,072]\n",
        "token_vecs_cat = []\n",
        "\n",
        "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for token in token_embeddings:\n",
        "    \n",
        "    # `token` is a [12 x 768] tensor\n",
        "\n",
        "    # Concatenate the vectors (that is, append them together) from the last \n",
        "    # four layers.\n",
        "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
        "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "    \n",
        "    # Use `cat_vec` to represent `token`.\n",
        "    token_vecs_cat.append(cat_vec)\n",
        "\n",
        "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape is: 38 x 3072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnWaByfelM-e"
      },
      "source": [
        "As an alternative method, let's try creating the word vectors by **summing** together the last four layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4DKDtFwiF0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35f8fdcc-6055-4ac5-d3a9-265791663e0d"
      },
      "source": [
        "# Stores the token vectors, with shape [22 x 768]\n",
        "token_vecs_sum = []\n",
        "\n",
        "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for token in token_embeddings:\n",
        "\n",
        "    # `token` is a [12 x 768] tensor\n",
        "\n",
        "    # Sum the vectors from the last four layers.\n",
        "    sum_vec = torch.sum(token[-4:], dim=0)\n",
        "    \n",
        "    # Use `sum_vec` to represent `token`.\n",
        "    token_vecs_sum.append(sum_vec)\n",
        "\n",
        "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape is: 38 x 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQaco6jRLkXn"
      },
      "source": [
        "### Sentence Vectors\n",
        "\n",
        "To get a single vector for our entire sentence we have multiple application-dependent strategies, but a simple approach is to average the second to last hiden layer of each token producing a single 768 length vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn0n2S-FWZih"
      },
      "source": [
        "# `encoded_layers` has shape [12 x 1 x 22 x 768]\n",
        "\n",
        "# `token_vecs` is a tensor with shape [22 x 768]\n",
        "token_vecs = encoded_layers[11][0]\n",
        "\n",
        "# Calculate the average of all 22 token vectors.\n",
        "sentence_embedding = torch.mean(token_vecs, dim=0)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQv0FL8VWadn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d056442-fed7-4415-fff3-da9517580fa8"
      },
      "source": [
        "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our final sentence embedding vector of shape: torch.Size([768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpuOCdqR7JfF",
        "outputId": "7bbb8180-414f-47a8-b1ca-424bb839fc46"
      },
      "source": [
        "tokenized_text"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'i',\n",
              " 'actually',\n",
              " 'love',\n",
              " 'apples',\n",
              " '.',\n",
              " 'apple',\n",
              " 'iphone',\n",
              " ',',\n",
              " 'mac',\n",
              " '##book',\n",
              " ',',\n",
              " 'air',\n",
              " '##pod',\n",
              " ',',\n",
              " 'air',\n",
              " '##book',\n",
              " '.',\n",
              " 'we',\n",
              " 'do',\n",
              " 'have',\n",
              " 'different',\n",
              " 'models',\n",
              " 'of',\n",
              " 'apple',\n",
              " 'phones',\n",
              " 'with',\n",
              " 'us',\n",
              " '.',\n",
              " 'what',\n",
              " 'was',\n",
              " 'the',\n",
              " 'conversation',\n",
              " 'regarding',\n",
              " 'apple',\n",
              " 'phone',\n",
              " '?',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyMOcl7X8TZf",
        "outputId": "f85e9865-0d64-44c9-a7df-2f8fbf820c3a"
      },
      "source": [
        "s = ''\n",
        "for i,j in enumerate(tokenized_text):\n",
        "  #print(j)\n",
        "  s = s +' ' +j\n",
        "  #s = i + ''.join(i)\n",
        "print(s)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [CLS] i actually love apples . apple iphone , mac ##book , air ##pod , air ##book . we do have different models of apple phones with us . what was the conversation regarding apple phone ? [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5J4kjh28mOT",
        "outputId": "0e8ffcc8-53c0-45a6-e98a-3531e13b07c3"
      },
      "source": [
        " s = s.split('.')\n",
        " s"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' [CLS] i actually love apples ',\n",
              " ' apple iphone , mac ##book , air ##pod , air ##book ',\n",
              " ' we do have different models of apple phones with us ',\n",
              " ' what was the conversation regarding apple phone ? [SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNiRsEh9cmWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0c30a45-8d23-44ec-ece9-85ccd385373a"
      },
      "source": [
        "for i, token_str in enumerate(tokenized_text):\n",
        "  print (i, token_str)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [CLS]\n",
            "1 i\n",
            "2 actually\n",
            "3 love\n",
            "4 apples\n",
            "5 .\n",
            "6 apple\n",
            "7 iphone\n",
            "8 ,\n",
            "9 mac\n",
            "10 ##book\n",
            "11 ,\n",
            "12 air\n",
            "13 ##pod\n",
            "14 ,\n",
            "15 air\n",
            "16 ##book\n",
            "17 .\n",
            "18 we\n",
            "19 do\n",
            "20 have\n",
            "21 different\n",
            "22 models\n",
            "23 of\n",
            "24 apple\n",
            "25 phones\n",
            "26 with\n",
            "27 us\n",
            "28 .\n",
            "29 what\n",
            "30 was\n",
            "31 the\n",
            "32 conversation\n",
            "33 regarding\n",
            "34 apple\n",
            "35 phone\n",
            "36 ?\n",
            "37 [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBa6vRHknSkv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e55287d4-d651-4620-e79d-3487cb3baf1c"
      },
      "source": [
        "print('First 5 vector values for each instance of \"apple\".')\n",
        "print('')\n",
        "print(\"love apples   \", str(token_vecs_sum[4][:5]))\n",
        "print(\"apple iphone  \", str(token_vecs_sum[6][:5]))\n",
        "print(\"apple phones   \", str(token_vecs_sum[24][:5]))\n",
        "print(\"apple phone   \", str(token_vecs_sum[34][:5]))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 vector values for each instance of \"apple\".\n",
            "\n",
            "love apples    tensor([-0.0389,  3.4002, -0.8703, -1.2919,  5.9360])\n",
            "apple iphone   tensor([ 1.7225,  5.9177,  0.9214, -1.2963,  4.1716])\n",
            "apple phones    tensor([1.1474, 3.3373, 0.0417, 2.1154, 4.0478])\n",
            "apple phone    tensor([1.6775, 3.1633, 0.4659, 0.3017, 4.3404])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca2TCQ_G7SM3"
      },
      "source": [
        "We can see that the values differ, but let's calculate the cosine similarity between the vectors to make a more precise comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYXUwiG0yhBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44209dc7-e8ae-490e-f55e-aacdb4ea1eaf"
      },
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "list = []\n",
        "diff = 1 - cosine(token_vecs_sum[4], token_vecs_sum[34])\n",
        "list.append(diff)\n",
        "same1 = 1 - cosine(token_vecs_sum[24], token_vecs_sum[34])\n",
        "list.append(same1)\n",
        "same = 1 - cosine(token_vecs_sum[6], token_vecs_sum[34])\n",
        "list.append(same)\n",
        "print('Vector similarity for  *similar*  meanings:  %.2f' % same1)\n",
        "print('Vector similarity for  *similar*  meanings:  %.2f' % same)\n",
        "print('Vector similarity for *different* meanings:  %.2f' % diff)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector similarity for  *similar*  meanings:  0.85\n",
            "Vector similarity for  *similar*  meanings:  0.74\n",
            "Vector similarity for *different* meanings:  0.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPk85m4WDAug",
        "outputId": "f237e7ca-e2ae-430b-d301-c58ab3f9d60d"
      },
      "source": [
        "list"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5761598348617554, 0.8513855338096619, 0.7413013577461243]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKb0UERQAx2D",
        "outputId": "2148947e-3477-42c1-bc7e-6d82ed9979e7"
      },
      "source": [
        "max(list)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8513855338096619"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FZ6UrdxODDei",
        "outputId": "3091217f-dda3-446b-9233-797e906405fa"
      },
      "source": [
        "s[1]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' apple iphone , mac ##book , air ##pod , air ##book '"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0QLDIowBwEF",
        "outputId": "29a48afd-e0fd-4f99-d0cc-10a7bb2627e8"
      },
      "source": [
        "for i in list:\n",
        "  print(i)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5761598348617554\n",
            "0.8513855338096619\n",
            "0.7413013577461243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lfb0DzJJDmBd",
        "outputId": "bffc5189-4849-41be-bf92-ea8e95a75d02"
      },
      "source": [
        "list.index(max(list))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQXcrixpAMK9",
        "outputId": "8cb84abd-3ecd-4175-bb87-a2a679fbb818"
      },
      "source": [
        "for i in range(3):\n",
        "    if i == list.index(max(list)):\n",
        "      print(\"The most similar sentence is: \",s[i])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most similar sentence is:   apple iphone , mac ##book , air ##pod , air ##book \n"
          ]
        }
      ]
    }
  ]
}